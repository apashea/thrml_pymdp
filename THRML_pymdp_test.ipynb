{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required Python libraries first\n",
        "!pip install jax jaxlib equinox\n",
        "\n",
        "# Remove any existing clones to avoid [already exists] errors\n",
        "!rm -rf /content/pymdp\n",
        "!rm -rf /content/thrml\n",
        "\n",
        "# Clone both GitHub repositories\n",
        "!git clone https://github.com/apashea/pymdp.git /content/pymdp\n",
        "!git clone https://github.com/extropic-ai/thrml.git /content/thrml\n",
        "\n",
        "# Install both as editable pip packages to generate proper metadata (required for importlib.metadata.version)\n",
        "!pip install -e /content/pymdp\n",
        "!pip install -e /content/thrml\n",
        "\n",
        "# Now import both libraries\n",
        "import pymdp\n",
        "import thrml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5UmYoPhIOmR",
        "outputId": "c0ce0816-4ed3-411f-f9ac-6405e6b3cb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (0.7.2)\n",
            "Requirement already satisfied: equinox in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax) (0.5.3)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax) (1.16.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.20 in /usr/local/lib/python3.12/dist-packages (from equinox) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from equinox) (4.15.0)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from equinox) (0.1.7)\n",
            "Cloning into '/content/pymdp'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 54 (delta 3), reused 42 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (54/54), 146.76 KiB | 1.29 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Cloning into '/content/thrml'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 129 (delta 30), reused 13 (delta 12), pack-reused 77 (from 1)\u001b[K\n",
            "Receiving objects: 100% (129/129), 33.55 MiB | 17.47 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "Obtaining file:///content/pymdp\n",
            "\u001b[31mERROR: file:///content/pymdp does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/thrml\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: equinox>=0.11.2 in /usr/local/lib/python3.12/dist-packages (from thrml==0.1.3) (0.13.2)\n",
            "Requirement already satisfied: jaxtyping>=0.2.23 in /usr/local/lib/python3.12/dist-packages (from thrml==0.1.3) (0.3.3)\n",
            "Requirement already satisfied: jax!=0.7.0,!=0.7.1,>=0.4.38 in /usr/local/lib/python3.12/dist-packages (from equinox>=0.11.2->thrml==0.1.3) (0.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from equinox>=0.11.2->thrml==0.1.3) (4.15.0)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from equinox>=0.11.2->thrml==0.1.3) (0.1.7)\n",
            "Requirement already satisfied: jaxlib<=0.7.2,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox>=0.11.2->thrml==0.1.3) (0.7.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox>=0.11.2->thrml==0.1.3) (0.5.3)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox>=0.11.2->thrml==0.1.3) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox>=0.11.2->thrml==0.1.3) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax!=0.7.0,!=0.7.1,>=0.4.38->equinox>=0.11.2->thrml==0.1.3) (1.16.3)\n",
            "Building wheels for collected packages: thrml\n",
            "  Building editable for thrml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thrml: filename=thrml-0.1.3-0.editable-py3-none-any.whl size=8629 sha256=b6e524e3a3383b8779d7423a46eb5667bceca1a8b221cd9ae0a5befe1c123057\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mu6hk9au/wheels/9e/59/97/898650a07a7e9df682df8fa675cea37149e3fc90ef631c365d\n",
            "Successfully built thrml\n",
            "Installing collected packages: thrml\n",
            "Successfully installed thrml-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "# THRML imports - corrected paths\n",
        "from thrml.models import CategoricalEBMFactor, CategoricalGibbsConditional, FactorizedEBM\n",
        "from thrml.pgm import CategoricalNode\n",
        "from thrml.block_management import Block\n",
        "from thrml.block_sampling import BlockGibbsSpec, SamplingSchedule, sample_states\n",
        "from thrml.factor import FactorSamplingProgram\n",
        "\n",
        "import pymdp\n",
        "from pymdp import utils\n",
        "from pymdp.agent import Agent\n",
        "\n",
        "# ============================================================================\n",
        "# SETUP: Define the minimal POMDP\n",
        "# ============================================================================\n",
        "\n",
        "# Problem specification\n",
        "n_states = 3  # Number of discrete hidden states\n",
        "n_obs = 2     # Number of discrete observations\n",
        "T = 5         # Time horizon (short for fast testing)\n",
        "\n",
        "# Random seed for reproducibility\n",
        "key = jax.random.key(42)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Define generative model parameters (shared by both THRML and pymdp)\n",
        "# ============================================================================\n",
        "\n",
        "# A matrix: Observation model P(o|s)\n",
        "# Shape: (n_obs, n_states)\n",
        "A_matrix = jnp.array([\n",
        "    [0.8, 0.1, 0.1],   # P(o=0 | s=0,1,2)\n",
        "    [0.2, 0.9, 0.9]    # P(o=1 | s=0,1,2)\n",
        "])\n",
        "\n",
        "# B matrix: Transition model P(s_t+1 | s_t)\n",
        "# Shape: (n_states, n_states)\n",
        "# B[i, j] = P(s_t+1=i | s_t=j)\n",
        "B_matrix = jnp.array([\n",
        "    [0.7, 0.2, 0.1],   # P(s'=0 | s=0,1,2)\n",
        "    [0.2, 0.6, 0.2],   # P(s'=1 | s=0,1,2)\n",
        "    [0.1, 0.2, 0.7]    # P(s'=2 | s=0,1,2)\n",
        "])\n",
        "\n",
        "# D vector: Initial state prior P(s_0)\n",
        "# Shape: (n_states,)\n",
        "D_vector = jnp.array([0.33, 0.33, 0.34])  # Approximately uniform\n",
        "\n",
        "# Generate synthetic observations for testing\n",
        "key, subkey = jax.random.split(key)\n",
        "observed_data = jax.random.randint(subkey, (T,), minval=0, maxval=n_obs, dtype=jnp.uint8)\n",
        "print(f\"Observed data: {observed_data}\")\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TEST 1: Matrix Convention Verification\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION TEST 1: Matrix Convention Verification\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Manually verify that THRML's transposed A matrix represents the same model\n",
        "# Check: P(o=1|s=0) should be 0.2 in both representations\n",
        "print(\"\\nVerifying A matrix conventions:\")\n",
        "print(f\"  Original A_matrix[1, 0] (P(o=1|s=0)): {A_matrix[1, 0]}\")\n",
        "print(f\"  Transposed log_A.T[0, 1] (exp of log P(o=1|s=0)): {jnp.exp(jnp.log(A_matrix[1, 0] + 1e-16))}\")\n",
        "print(f\"  ✓ Match: {jnp.allclose(A_matrix[1, 0], jnp.exp(jnp.log(A_matrix[1, 0] + 1e-16)))}\")\n",
        "\n",
        "# Verify B matrix\n",
        "print(\"\\nVerifying B matrix conventions:\")\n",
        "print(f\"  B_matrix[0, 1] (P(s'=0|s=1)): {B_matrix[0, 1]}\")\n",
        "print(f\"  ✓ THRML uses same B matrix (no transpose needed)\")\n",
        "\n",
        "# Verify D vector\n",
        "print(\"\\nVerifying D vector:\")\n",
        "print(f\"  D_vector: {D_vector}\")\n",
        "print(f\"  Sum (should be ~1.0): {jnp.sum(D_vector):.6f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Build THRML model (smoothing inference)\n",
        "# ============================================================================\n",
        "\n",
        "# Create temporal chain of nodes\n",
        "state_nodes = [CategoricalNode() for _ in range(T)]\n",
        "obs_nodes = [CategoricalNode() for _ in range(T)]\n",
        "\n",
        "# Convert probability matrices to log-space for THRML\n",
        "log_A = jnp.log(A_matrix + 1e-16)  # Shape: (n_obs, n_states) = (2, 3)\n",
        "log_B = jnp.log(B_matrix + 1e-16)\n",
        "log_D = jnp.log(D_vector + 1e-16)\n",
        "\n",
        "# Observation factor: P(o_t | s_t) for all t\n",
        "# IMPORTANT: Transpose A matrix to match block order [states, obs]\n",
        "log_A_transposed = log_A.T  # Shape: (n_states, n_obs) = (3, 2)\n",
        "log_A_temporal = jnp.tile(log_A_transposed[None, :, :], (T, 1, 1))  # Shape: (T, n_states, n_obs) = (5, 3, 2)\n",
        "\n",
        "obs_factor = CategoricalEBMFactor(\n",
        "    [Block(state_nodes), Block(obs_nodes)],\n",
        "    log_A_temporal  # Shape: (T, n_states, n_obs)\n",
        ")\n",
        "\n",
        "# Transition factor: P(s_t+1 | s_t) for t=0..T-2\n",
        "# Weight tensor shape: (T-1, n_states, n_states)\n",
        "# Note: B_matrix is (n_states, n_states), so we tile it T-1 times\n",
        "log_B_temporal = jnp.tile(log_B[None, :, :], (T-1, 1, 1))\n",
        "\n",
        "transition_factor = CategoricalEBMFactor(\n",
        "    [Block(state_nodes[:-1]), Block(state_nodes[1:])],\n",
        "    log_B_temporal\n",
        ")\n",
        "\n",
        "# Prior factor: P(s_0) - only applies to first state\n",
        "# Weight tensor shape: (1, n_states)\n",
        "prior_factor = CategoricalEBMFactor(\n",
        "    [Block([state_nodes[0]])],\n",
        "    log_D[None, :]\n",
        ")\n",
        "\n",
        "# Combine into EBM\n",
        "ebm = FactorizedEBM([obs_factor, transition_factor, prior_factor])\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TEST 2: Energy Function Verification\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION TEST 2: Energy Function Verification\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test energy computation for a known configuration\n",
        "test_states = jnp.array([0, 0, 0, 0, 0], dtype=jnp.uint8)  # All states = 0\n",
        "test_energy = ebm.energy([test_states, observed_data], [Block(state_nodes), Block(obs_nodes)])\n",
        "\n",
        "# Manually compute expected energy\n",
        "# Energy = -log P(states, obs) = -[log P(s_0) + sum_t log P(o_t|s_t) + sum_t log P(s_t+1|s_t)]\n",
        "manual_energy = -log_D[0]  # Prior for s_0=0\n",
        "for t in range(T):\n",
        "    manual_energy -= log_A_transposed[0, observed_data[t]]  # Observation likelihood\n",
        "for t in range(T-1):\n",
        "    manual_energy -= log_B[0, 0]  # Transition s_t=0 -> s_t+1=0\n",
        "\n",
        "print(f\"\\nEnergy for all-zero state sequence:\")\n",
        "print(f\"  THRML computed energy: {test_energy:.6f}\")\n",
        "print(f\"  Manually computed energy: {manual_energy:.6f}\")\n",
        "print(f\"  ✓ Match: {jnp.allclose(test_energy, manual_energy, rtol=1e-5)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: Set up THRML sampling program\n",
        "# ============================================================================\n",
        "\n",
        "# Gibbs spec: states are free (to be inferred), observations are clamped\n",
        "gibbs_spec = BlockGibbsSpec(\n",
        "    free_super_blocks=[Block(state_nodes)],  # Changed from free_blocks\n",
        "    clamped_blocks=[Block(obs_nodes)]\n",
        ")\n",
        "\n",
        "# Sampler for categorical states\n",
        "sampler = CategoricalGibbsConditional(n_states)\n",
        "\n",
        "# Create sampling program\n",
        "prog = FactorSamplingProgram(\n",
        "    gibbs_spec,\n",
        "    [sampler],\n",
        "    [obs_factor, transition_factor, prior_factor],\n",
        "    []\n",
        ")\n",
        "\n",
        "# Initialize states randomly\n",
        "key, subkey = jax.random.split(key)\n",
        "init_states = jax.random.randint(subkey, (T,), 0, n_states, dtype=jnp.uint8)\n",
        "\n",
        "# Sampling schedule\n",
        "schedule = SamplingSchedule(\n",
        "    n_warmup=100,      # Burn-in iterations\n",
        "    n_samples=1000,    # Collect 1000 samples\n",
        "    steps_per_sample=2 # 2 Gibbs sweeps between samples\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: Run THRML inference (smoothing)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Running THRML smoothing inference...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "key, subkey = jax.random.split(key)\n",
        "samples = sample_states(\n",
        "    subkey,\n",
        "    prog,\n",
        "    schedule,\n",
        "    [init_states],\n",
        "    [observed_data],\n",
        "    [Block(state_nodes)]\n",
        ")\n",
        "\n",
        "# Compute empirical marginals from samples\n",
        "# samples[0] has shape: (n_samples, T)\n",
        "state_samples = samples[0]\n",
        "marginals_thrml = jnp.mean(\n",
        "    jax.nn.one_hot(state_samples, n_states),\n",
        "    axis=0\n",
        ")  # Shape: (T, n_states)\n",
        "\n",
        "print(\"\\nTHRML smoothing posteriors P(s_t | o_0:T-1):\")\n",
        "for t in range(T):\n",
        "    print(f\"  t={t}: {marginals_thrml[t]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: Build pymdp model and run sequential filtering\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Running pymdp sequential filtering...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Convert THRML model to pymdp format\n",
        "# Our A_matrix is (n_obs, n_states) = (2, 3)\n",
        "A_pymdp = utils.obj_array(1)\n",
        "A_pymdp[0] = np.array(A_matrix)  # Transpose: (n_states, n_obs) = (3, 2)\n",
        "\n",
        "A_pymdp[0] = utils.norm_dist(A_pymdp[0])\n",
        "print(f\"is A_pymdp[0] normalized? : {utils.is_normalized(A_pymdp[0])}\")\n",
        "\n",
        "# pymdp B matrix: B[s', s] (same as our B_matrix)\n",
        "B_pymdp = utils.obj_array(1)\n",
        "\n",
        "# Add action dimension: shape (n_states, n_states, 1)\n",
        "# B_pymdp[0][s', s, 0] = P(s'|s) for the single null action\n",
        "B_matrix_with_action = np.expand_dims(np.array(B_matrix), axis=2)\n",
        "\n",
        "B_pymdp[0] = B_matrix_with_action  # Shape: (3, 3, 1)\n",
        "\n",
        "# Verify shape\n",
        "print(f\"B_pymdp[0] shape: {B_pymdp[0].shape}\")  # Should be (3, 3, 1)\n",
        "\n",
        "# pymdp D vector: initial state prior\n",
        "D_pymdp = utils.obj_array(1)\n",
        "D_pymdp[0] = np.array(D_vector)\n",
        "\n",
        "# Create pymdp agent with explicit inference algorithm\n",
        "agent = Agent(\n",
        "    A=A_pymdp,\n",
        "    B=B_pymdp,\n",
        "    D=D_pymdp,\n",
        "    inference_algo=\"VANILLA\"  # Explicit FPI for filtering\n",
        ")\n",
        "\n",
        "# Process observations ONE AT A TIME (sequential filtering)\n",
        "qs_pymdp_history = []\n",
        "for t, obs in enumerate(observed_data):\n",
        "    observation = [int(obs)]  # Single observation for single modality\n",
        "    qs = agent.infer_states(observation)\n",
        "    q_pi, neg_efe = agent.infer_policies()\n",
        "    action_idx = agent.sample_action()\n",
        "    qs_pymdp_history.append(qs[0])  # Extract state factor 0\n",
        "    print(f\"  t={t}: pymdp filtering P(s_{t} | o_0:{t}) = {qs[0]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: Compare results\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nNote: THRML computes smoothing P(s_t | o_0:T-1) while\")\n",
        "print(\"      pymdp computes filtering P(s_t | o_0:t)\")\n",
        "print(\"      These are different inference problems!\\n\")\n",
        "\n",
        "# Compare final timestep (where both have seen all observations)\n",
        "final_qs_pymdp = qs_pymdp_history[-1]\n",
        "final_marginal_thrml = marginals_thrml[-1]\n",
        "\n",
        "print(f\"Final timestep (t={T-1}) comparison:\")\n",
        "print(f\"  pymdp filtering:  {final_qs_pymdp}\")\n",
        "print(f\"  THRML smoothing:  {final_marginal_thrml}\")\n",
        "\n",
        "error = jnp.max(jnp.abs(final_marginal_thrml - final_qs_pymdp))\n",
        "print(f\"\\nMax absolute error at final timestep: {error:.4f}\")\n",
        "\n",
        "# Success criterion\n",
        "if error < 0.05:\n",
        "    print(\"\\n✓ SUCCESS: Error < 5%, THRML approximates pymdp well!\")\n",
        "else:\n",
        "    print(f\"\\n✗ WARNING: Error = {error:.4f} >= 5%\")\n",
        "    print(\"  Consider increasing n_samples or n_warmup in THRML\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: Full comparison across all timesteps (for reference)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FULL TIMESTEP COMPARISON (for reference)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nTimestep-by-timestep comparison:\")\n",
        "for t in range(T):\n",
        "    error_t = jnp.max(jnp.abs(marginals_thrml[t] - qs_pymdp_history[t]))\n",
        "    print(f\"  t={t}: max_error = {error_t:.4f}\")\n",
        "    print(f\"    pymdp filtering:  {qs_pymdp_history[t]}\")\n",
        "    print(f\"    THRML smoothing:  {marginals_thrml[t]}\")\n",
        "\n",
        "print(\"\\nNote: Errors at early timesteps are expected to be larger\")\n",
        "print(\"      because THRML uses future observations (smoothing)\")\n",
        "print(\"      while pymdp only uses past observations (filtering).\")\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TEST 1: Matrix Convention Verification\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION TEST 1: Matrix Convention Verification\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Manually verify that A matrices represent the same model\n",
        "print(\"\\nVerifying A matrix conventions:\")\n",
        "print(f\"Original A_matrix[o=0, s=0] = {A_matrix[0, 0]:.3f}\")\n",
        "print(f\"  This means P(o=0 | s=0) = {A_matrix[0, 0]:.3f}\")\n",
        "\n",
        "print(f\"\\nTHRML log_A_transposed[s=0, o=0] = {jnp.exp(log_A_transposed[0, 0]):.3f}\")\n",
        "print(f\"  This means P(o=0 | s=0) = {jnp.exp(log_A_transposed[0, 0]):.3f}\")\n",
        "\n",
        "print(f\"\\npymdp A_pymdp[0][s=0, o=0] = {A_pymdp[0][0, 0]:.3f}\")\n",
        "print(f\"  This means P(o=0 | s=0) = {A_pymdp[0][0, 0]:.3f}\")\n",
        "\n",
        "# Check if they match\n",
        "thrml_prob = float(jnp.exp(log_A_transposed[0, 0]))\n",
        "pymdp_prob = float(A_pymdp[0][0, 0])\n",
        "original_prob = float(A_matrix[0, 0])\n",
        "\n",
        "if jnp.allclose(thrml_prob, original_prob, atol=1e-6) and jnp.allclose(pymdp_prob, original_prob, atol=1e-6):\n",
        "    print(\"\\n✓ Matrix conventions are correctly aligned!\")\n",
        "else:\n",
        "    print(\"\\n✗ WARNING: Matrix conventions may not be aligned!\")\n",
        "    print(f\"  THRML: {thrml_prob:.6f}, pymdp: {pymdp_prob:.6f}, original: {original_prob:.6f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TEST 2: Energy Function Verification\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION TEST 2: Energy Function Verification\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test energy computation for a known configuration\n",
        "test_states = jnp.array([0, 0, 0, 0, 0], dtype=jnp.uint8)  # All states = 0\n",
        "test_obs = observed_data  # Use actual observations\n",
        "\n",
        "print(f\"\\nTesting energy for state configuration: {test_states}\")\n",
        "print(f\"With observations: {test_obs}\")\n",
        "\n",
        "# Compute energy using THRML\n",
        "energy_thrml = ebm.energy(\n",
        "    [test_states, test_obs],\n",
        "    [Block(state_nodes), Block(obs_nodes)]\n",
        ")\n",
        "\n",
        "print(f\"\\nTHRML energy: {energy_thrml:.4f}\")\n",
        "\n",
        "# Manually compute expected energy\n",
        "# Energy = -sum(log P(o_t | s_t)) - sum(log P(s_t+1 | s_t)) - log P(s_0)\n",
        "manual_energy = 0.0\n",
        "\n",
        "# Initial state prior contribution\n",
        "manual_energy -= float(log_D[test_states[0]])\n",
        "\n",
        "# Observation contributions\n",
        "for t in range(T):\n",
        "    manual_energy -= float(log_A_transposed[test_states[t], test_obs[t]])\n",
        "\n",
        "# Transition contributions\n",
        "for t in range(T-1):\n",
        "    manual_energy -= float(log_B[test_states[t+1], test_states[t]])\n",
        "\n",
        "print(f\"Manually computed energy: {manual_energy:.4f}\")\n",
        "\n",
        "if jnp.allclose(energy_thrml, manual_energy, atol=1e-4):\n",
        "    print(\"\\n✓ Energy function is correctly implemented!\")\n",
        "else:\n",
        "    print(f\"\\n✗ WARNING: Energy mismatch! Difference: {abs(energy_thrml - manual_energy):.6f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TEST 3: Multiple Trial Runs (Sampling Convergence)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION TEST 3: Multiple Trial Runs (Sampling Convergence)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nRunning 5 trials with different random seeds...\")\n",
        "\n",
        "n_trials = 5\n",
        "trial_errors = []\n",
        "\n",
        "for trial_idx in range(n_trials):\n",
        "    # Use different random seed for each trial\n",
        "    trial_key = jax.random.key(42 + trial_idx)\n",
        "\n",
        "    # Split key for initialization and sampling\n",
        "    trial_key, init_key, samp_key = jax.random.split(trial_key, 3)\n",
        "\n",
        "    # Initialize state\n",
        "    trial_init_states = [jax.random.randint(init_key, (T,), 0, n_states, dtype=jnp.uint8)]\n",
        "\n",
        "    # Run sampling\n",
        "    trial_samples = sample_states(\n",
        "        samp_key,\n",
        "        prog,\n",
        "        schedule,\n",
        "        trial_init_states,\n",
        "        [observed_data],\n",
        "        [Block(state_nodes)]\n",
        "    )\n",
        "\n",
        "    # Extract the state samples (first element of list, shape: (n_samples, T))\n",
        "    state_samples = trial_samples[0]  # Shape: (n_samples, T)\n",
        "\n",
        "    # Compute empirical marginals for each timestep\n",
        "    trial_marginals = []\n",
        "    for t in range(T):\n",
        "        # Get samples at timestep t: shape (n_samples,)\n",
        "        samples_at_t = state_samples[:, t]\n",
        "        # Count occurrences of each state\n",
        "        counts = jnp.bincount(samples_at_t, length=n_states)\n",
        "        # Normalize to get marginal distribution\n",
        "        marginal = counts / schedule.n_samples\n",
        "        trial_marginals.append(marginal)\n",
        "\n",
        "    # Compare with pymdp at final timestep\n",
        "    trial_error = jnp.max(jnp.abs(trial_marginals[-1] - qs_pymdp_history[-1]))\n",
        "    trial_errors.append(float(trial_error))\n",
        "\n",
        "    print(f\"  Trial {trial_idx + 1}: final timestep error = {trial_error:.4f}\")\n",
        "\n",
        "# Compute statistics\n",
        "mean_error = np.mean(trial_errors)\n",
        "std_error = np.std(trial_errors)\n",
        "\n",
        "print(f\"\\nMultiple trial statistics:\")\n",
        "print(f\"  Mean error: {mean_error:.4f}\")\n",
        "print(f\"  Std error: {std_error:.4f}\")\n",
        "\n",
        "if mean_error < 0.05 and std_error < 0.02:\n",
        "    print(\"\\n✓ Sampling is stable across trials!\")\n",
        "elif mean_error < 0.10:\n",
        "    print(\"\\n⚠ Acceptable stability, but consider more samples\")\n",
        "else:\n",
        "    print(\"\\n✗ High variance across trials - increase n_samples\")\n",
        "\n",
        "# ============================================================================\n",
        "# VALIDATION TEST 4: Increased Sample Size Test\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION TEST 4: Increased Sample Size Test\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nTesting with 10x more samples (10,000 samples)...\")\n",
        "\n",
        "# Create schedule with 10x more samples\n",
        "large_schedule = SamplingSchedule(\n",
        "    n_warmup=100,\n",
        "    n_samples=10000,  # 10x increase\n",
        "    steps_per_sample=2\n",
        ")\n",
        "\n",
        "# Create FRESH initial states for this test (don't reuse init_states)\n",
        "key, large_init_key, large_samp_key = jax.random.split(key, 3)\n",
        "large_init_states = [jax.random.randint(large_init_key, (T,), 0, n_states, dtype=jnp.uint8)]\n",
        "\n",
        "# Run sampling with larger sample size\n",
        "large_samples = sample_states(\n",
        "    large_samp_key,\n",
        "    prog,\n",
        "    large_schedule,\n",
        "    large_init_states,  # ✓ Use fresh initial states\n",
        "    [observed_data],\n",
        "    [Block(state_nodes)]\n",
        ")\n",
        "\n",
        "# Extract the state samples (first element of list, shape: (10000, T))\n",
        "large_state_samples = large_samples[0]  # Shape: (10000, T)\n",
        "\n",
        "# Compute empirical marginals for each timestep\n",
        "large_marginals = []\n",
        "for t in range(T):\n",
        "    # Get samples at timestep t: shape (10000,)\n",
        "    samples_at_t = large_state_samples[:, t]\n",
        "    # Count occurrences of each state\n",
        "    counts = jnp.bincount(samples_at_t, length=n_states)\n",
        "    # Normalize to get marginal distribution\n",
        "    marginal = counts / large_schedule.n_samples\n",
        "    large_marginals.append(marginal)\n",
        "\n",
        "# Compare with pymdp at final timestep\n",
        "large_error = jnp.max(jnp.abs(large_marginals[-1] - qs_pymdp_history[-1]))\n",
        "\n",
        "print(f\"\\nFinal timestep error with 10,000 samples: {large_error:.4f}\")\n",
        "print(f\"Original error with 1,000 samples: {error:.4f}\")\n",
        "\n",
        "if large_error < error:\n",
        "    print(\"\\n✓ Error decreased with more samples (expected behavior)\")\n",
        "else:\n",
        "    print(\"\\n⚠ Error did not decrease (may indicate sampling has converged)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. Final timestep comparison:\")\n",
        "print(f\"   Error: {error:.4f} {'✓ PASS' if error < 0.05 else '✗ FAIL'}\")\n",
        "\n",
        "print(\"\\n2. Matrix convention verification:\")\n",
        "print(f\"   {'✓ PASS' if jnp.allclose(thrml_prob, original_prob, atol=1e-6) else '✗ FAIL'}\")\n",
        "\n",
        "print(\"\\n3. Energy function verification:\")\n",
        "print(f\"   {'✓ PASS' if jnp.allclose(energy_thrml, manual_energy, atol=1e-4) else '✗ FAIL'}\")\n",
        "\n",
        "print(\"\\n4. Multiple trial stability:\")\n",
        "print(f\"   Mean error: {mean_error:.4f}, Std: {std_error:.4f}\")\n",
        "print(f\"   {'✓ PASS' if mean_error < 0.05 and std_error < 0.02 else '⚠ ACCEPTABLE' if mean_error < 0.10 else '✗ FAIL'}\")\n",
        "\n",
        "print(\"\\n5. Increased sample size test:\")\n",
        "print(f\"   Error with 10x samples: {large_error:.4f}\")\n",
        "print(f\"   {'✓ PASS' if large_error < error else '⚠ NOTE'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"All validation tests complete!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjIJXSmlSo7I",
        "outputId": "5815879c-4ff4-4c45-a72c-12bcba33d503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed data: [1 0 0 0 1]\n",
            "\n",
            "============================================================\n",
            "VALIDATION TEST 1: Matrix Convention Verification\n",
            "============================================================\n",
            "\n",
            "Verifying A matrix conventions:\n",
            "  Original A_matrix[1, 0] (P(o=1|s=0)): 0.20000000298023224\n",
            "  Transposed log_A.T[0, 1] (exp of log P(o=1|s=0)): 0.19999998807907104\n",
            "  ✓ Match: True\n",
            "\n",
            "Verifying B matrix conventions:\n",
            "  B_matrix[0, 1] (P(s'=0|s=1)): 0.20000000298023224\n",
            "  ✓ THRML uses same B matrix (no transpose needed)\n",
            "\n",
            "Verifying D vector:\n",
            "  D_vector: [0.33 0.33 0.34]\n",
            "  Sum (should be ~1.0): 1.000000\n",
            "\n",
            "============================================================\n",
            "VALIDATION TEST 2: Energy Function Verification\n",
            "============================================================\n",
            "\n",
            "Energy for all-zero state sequence:\n",
            "  THRML computed energy: 6.423669\n",
            "  Manually computed energy: 6.423670\n",
            "  ✓ Match: True\n",
            "\n",
            "============================================================\n",
            "Running THRML smoothing inference...\n",
            "============================================================\n",
            "\n",
            "THRML smoothing posteriors P(s_t | o_0:T-1):\n",
            "  t=0: [0.30900002 0.45400003 0.23700002]\n",
            "  t=1: [0.8880001 0.066     0.046    ]\n",
            "  t=2: [0.95400006 0.032      0.014     ]\n",
            "  t=3: [0.88000005 0.07300001 0.047     ]\n",
            "  t=4: [0.29200003 0.462      0.246     ]\n",
            "\n",
            "============================================================\n",
            "Running pymdp sequential filtering...\n",
            "============================================================\n",
            "is A_pymdp[0] normalized? : True\n",
            "B_pymdp[0] shape: (3, 3, 1)\n",
            "  t=0: pymdp filtering P(s_0 | o_0:0) = [0.09865471 0.44394618 0.45739911]\n",
            "  t=1: pymdp filtering P(s_1 | o_0:1) = [0.67159763 0.15569527 0.1727071 ]\n",
            "  t=2: pymdp filtering P(s_2 | o_0:2) = [0.89600358 0.05665125 0.04734517]\n",
            "  t=3: pymdp filtering P(s_3 | o_0:3) = [0.93517334 0.04046261 0.02436405]\n",
            "  t=4: pymdp filtering P(s_4 | o_0:4) = [0.30624227 0.44790254 0.24585519]\n",
            "\n",
            "============================================================\n",
            "COMPARISON\n",
            "============================================================\n",
            "\n",
            "Note: THRML computes smoothing P(s_t | o_0:T-1) while\n",
            "      pymdp computes filtering P(s_t | o_0:t)\n",
            "      These are different inference problems!\n",
            "\n",
            "Final timestep (t=4) comparison:\n",
            "  pymdp filtering:  [0.30624227 0.44790254 0.24585519]\n",
            "  THRML smoothing:  [0.29200003 0.462      0.246     ]\n",
            "\n",
            "Max absolute error at final timestep: 0.0142\n",
            "\n",
            "✓ SUCCESS: Error < 5%, THRML approximates pymdp well!\n",
            "\n",
            "============================================================\n",
            "FULL TIMESTEP COMPARISON (for reference)\n",
            "============================================================\n",
            "\n",
            "Timestep-by-timestep comparison:\n",
            "  t=0: max_error = 0.2204\n",
            "    pymdp filtering:  [0.09865471 0.44394618 0.45739911]\n",
            "    THRML smoothing:  [0.30900002 0.45400003 0.23700002]\n",
            "  t=1: max_error = 0.2164\n",
            "    pymdp filtering:  [0.67159763 0.15569527 0.1727071 ]\n",
            "    THRML smoothing:  [0.8880001 0.066     0.046    ]\n",
            "  t=2: max_error = 0.0580\n",
            "    pymdp filtering:  [0.89600358 0.05665125 0.04734517]\n",
            "    THRML smoothing:  [0.95400006 0.032      0.014     ]\n",
            "  t=3: max_error = 0.0552\n",
            "    pymdp filtering:  [0.93517334 0.04046261 0.02436405]\n",
            "    THRML smoothing:  [0.88000005 0.07300001 0.047     ]\n",
            "  t=4: max_error = 0.0142\n",
            "    pymdp filtering:  [0.30624227 0.44790254 0.24585519]\n",
            "    THRML smoothing:  [0.29200003 0.462      0.246     ]\n",
            "\n",
            "Note: Errors at early timesteps are expected to be larger\n",
            "      because THRML uses future observations (smoothing)\n",
            "      while pymdp only uses past observations (filtering).\n",
            "\n",
            "============================================================\n",
            "VALIDATION TEST 1: Matrix Convention Verification\n",
            "============================================================\n",
            "\n",
            "Verifying A matrix conventions:\n",
            "Original A_matrix[o=0, s=0] = 0.800\n",
            "  This means P(o=0 | s=0) = 0.800\n",
            "\n",
            "THRML log_A_transposed[s=0, o=0] = 0.800\n",
            "  This means P(o=0 | s=0) = 0.800\n",
            "\n",
            "pymdp A_pymdp[0][s=0, o=0] = 0.800\n",
            "  This means P(o=0 | s=0) = 0.800\n",
            "\n",
            "✓ Matrix conventions are correctly aligned!\n",
            "\n",
            "============================================================\n",
            "VALIDATION TEST 2: Energy Function Verification\n",
            "============================================================\n",
            "\n",
            "Testing energy for state configuration: [0 0 0 0 0]\n",
            "With observations: [1 0 0 0 1]\n",
            "\n",
            "THRML energy: 6.4237\n",
            "Manually computed energy: 6.4237\n",
            "\n",
            "✓ Energy function is correctly implemented!\n",
            "\n",
            "============================================================\n",
            "VALIDATION TEST 3: Multiple Trial Runs (Sampling Convergence)\n",
            "============================================================\n",
            "\n",
            "Running 5 trials with different random seeds...\n",
            "  Trial 1: final timestep error = 0.0261\n",
            "  Trial 2: final timestep error = 0.0129\n",
            "  Trial 3: final timestep error = 0.0171\n",
            "  Trial 4: final timestep error = 0.0159\n",
            "  Trial 5: final timestep error = 0.0061\n",
            "\n",
            "Multiple trial statistics:\n",
            "  Mean error: 0.0156\n",
            "  Std error: 0.0065\n",
            "\n",
            "✓ Sampling is stable across trials!\n",
            "\n",
            "============================================================\n",
            "VALIDATION TEST 4: Increased Sample Size Test\n",
            "============================================================\n",
            "\n",
            "Testing with 10x more samples (10,000 samples)...\n",
            "\n",
            "Final timestep error with 10,000 samples: 0.0033\n",
            "Original error with 1,000 samples: 0.0142\n",
            "\n",
            "✓ Error decreased with more samples (expected behavior)\n",
            "\n",
            "============================================================\n",
            "VALIDATION SUMMARY\n",
            "============================================================\n",
            "\n",
            "1. Final timestep comparison:\n",
            "   Error: 0.0142 ✓ PASS\n",
            "\n",
            "2. Matrix convention verification:\n",
            "   ✓ PASS\n",
            "\n",
            "3. Energy function verification:\n",
            "   ✓ PASS\n",
            "\n",
            "4. Multiple trial stability:\n",
            "   Mean error: 0.0156, Std: 0.0065\n",
            "   ✓ PASS\n",
            "\n",
            "5. Increased sample size test:\n",
            "   Error with 10x samples: 0.0033\n",
            "   ✓ PASS\n",
            "\n",
            "============================================================\n",
            "All validation tests complete!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}